apiVersion: v1
automountServiceAccountToken: false
kind: ServiceAccount
metadata:
  labels:
    app.kubernetes.io/component: zookeeper
    app.kubernetes.io/instance: zookeeper-team1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/version: 3.9.3
    helm.sh/chart: zookeeper-13.6.0
    role: zookeeper
  name: zookeeper-team1
  namespace: zookeeper
---
apiVersion: v1
data:
  init-certs.sh: '#!/bin/bash'
  setup.sh: |-
    #!/bin/bash

    # Execute entrypoint as usual after obtaining ZOO_SERVER_ID
    # check ZOO_SERVER_ID in persistent volume via myid
    # if not present, set based on POD hostname
    if [[ -f "/bitnami/zookeeper/data/myid" ]]; then
        export ZOO_SERVER_ID="$(cat /bitnami/zookeeper/data/myid)"
    else
        HOSTNAME="$(hostname -s)"
        if [[ $HOSTNAME =~ (.*)-([0-9]+)$ ]]; then
            ORD=${BASH_REMATCH[2]}
            export ZOO_SERVER_ID="$((ORD + 1 ))"
        else
            echo "Failed to get index from hostname $HOSTNAME"
            exit 1
        fi
    fi
    exec /entrypoint.sh /run.sh
kind: ConfigMap
metadata:
  labels:
    app.kubernetes.io/component: zookeeper
    app.kubernetes.io/instance: zookeeper-team1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/version: 3.9.3
    helm.sh/chart: zookeeper-13.6.0
  name: zookeeper-team1-scripts
  namespace: zookeeper
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: zookeeper
    app.kubernetes.io/instance: zookeeper-team1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/version: 3.9.3
    helm.sh/chart: zookeeper-13.6.0
  name: zookeeper-team1
  namespace: zookeeper
spec:
  ports:
  - name: tcp-client
    nodePort: null
    port: 2181
    targetPort: client
  selector:
    app.kubernetes.io/component: zookeeper
    app.kubernetes.io/instance: zookeeper-team1
    app.kubernetes.io/name: zookeeper
  sessionAffinity: None
  type: ClusterIP
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/component: zookeeper
    app.kubernetes.io/instance: zookeeper-team1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/version: 3.9.3
    helm.sh/chart: zookeeper-13.6.0
  name: zookeeper-team1-headless
  namespace: zookeeper
spec:
  clusterIP: None
  ports:
  - name: tcp-client
    port: 2181
    targetPort: client
  - name: tcp-follower
    port: 2888
    targetPort: follower
  - name: tcp-election
    port: 3888
    targetPort: election
  publishNotReadyAddresses: true
  selector:
    app.kubernetes.io/component: zookeeper
    app.kubernetes.io/instance: zookeeper-team1
    app.kubernetes.io/name: zookeeper
  type: ClusterIP
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  labels:
    app.kubernetes.io/component: zookeeper
    app.kubernetes.io/instance: zookeeper-team1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/version: 3.9.3
    helm.sh/chart: zookeeper-13.6.0
    role: zookeeper
  name: zookeeper-team1
  namespace: zookeeper
spec:
  podManagementPolicy: Parallel
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/component: zookeeper
      app.kubernetes.io/instance: zookeeper-team1
      app.kubernetes.io/name: zookeeper
  serviceName: zookeeper-team1-headless
  template:
    metadata:
      annotations: null
      labels:
        app.kubernetes.io/component: zookeeper
        app.kubernetes.io/instance: zookeeper-team1
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: zookeeper
        app.kubernetes.io/version: 3.9.3
        helm.sh/chart: zookeeper-13.6.0
    spec:
      affinity:
        nodeAffinity: null
        podAffinity: null
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/component: zookeeper
                  app.kubernetes.io/instance: zookeeper-team1
                  app.kubernetes.io/name: zookeeper
              topologyKey: kubernetes.io/hostname
            weight: 1
      automountServiceAccountToken: false
      containers:
      - command:
        - /scripts/setup.sh
        env:
        - name: BITNAMI_DEBUG
          value: "false"
        - name: ZOO_DATA_LOG_DIR
          value: ""
        - name: ZOO_PORT_NUMBER
          value: "2181"
        - name: ZOO_TICK_TIME
          value: "2000"
        - name: ZOO_INIT_LIMIT
          value: "10"
        - name: ZOO_SYNC_LIMIT
          value: "5"
        - name: ZOO_PRE_ALLOC_SIZE
          value: "65536"
        - name: ZOO_SNAPCOUNT
          value: "100000"
        - name: ZOO_MAX_CLIENT_CNXNS
          value: "60"
        - name: ZOO_4LW_COMMANDS_WHITELIST
          value: srvr, mntr, ruok
        - name: ZOO_LISTEN_ALLIPS_ENABLED
          value: "no"
        - name: ZOO_AUTOPURGE_INTERVAL
          value: "1"
        - name: ZOO_AUTOPURGE_RETAIN_COUNT
          value: "10"
        - name: ZOO_MAX_SESSION_TIMEOUT
          value: "40000"
        - name: ZOO_SERVERS
          value: zookeeper-team1-0.zookeeper-team1-headless.zookeeper.svc.cluster.local:2888:3888::1
        - name: ZOO_ENABLE_AUTH
          value: "no"
        - name: ZOO_ENABLE_QUORUM_AUTH
          value: "no"
        - name: ZOO_HEAP_SIZE
          value: "1024"
        - name: ZOO_LOG_LEVEL
          value: ERROR
        - name: ALLOW_ANONYMOUS_LOGIN
          value: "yes"
        - name: POD_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.name
        - name: ZOO_ADMIN_SERVER_PORT_NUMBER
          value: "8080"
        image: docker.io/bitnami/zookeeper:3.9.3-debian-12-r0
        imagePullPolicy: IfNotPresent
        livenessProbe:
          exec:
            command:
            - /bin/bash
            - -ec
            - ZOO_HC_TIMEOUT=3 /opt/bitnami/scripts/zookeeper/healthcheck.sh
          failureThreshold: 6
          initialDelaySeconds: 30
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        name: zookeeper
        ports:
        - containerPort: 2181
          name: client
        - containerPort: 8080
          name: http-admin
        readinessProbe:
          exec:
            command:
            - /bin/bash
            - -ec
            - ZOO_HC_TIMEOUT=2 /opt/bitnami/scripts/zookeeper/healthcheck.sh
          failureThreshold: 6
          initialDelaySeconds: 5
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        resources:
          limits:
            cpu: 375m
            ephemeral-storage: 2Gi
            memory: 384Mi
          requests:
            cpu: 250m
            ephemeral-storage: 50Mi
            memory: 256Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          readOnlyRootFilesystem: true
          runAsGroup: 1001
          runAsNonRoot: true
          runAsUser: 1001
          seLinuxOptions: {}
          seccompProfile:
            type: RuntimeDefault
        volumeMounts:
        - mountPath: /tmp
          name: empty-dir
          subPath: tmp-dir
        - mountPath: /opt/bitnami/zookeeper/conf
          name: empty-dir
          subPath: app-conf-dir
        - mountPath: /opt/bitnami/zookeeper/logs
          name: empty-dir
          subPath: app-logs-dir
        - mountPath: /scripts/setup.sh
          name: scripts
          subPath: setup.sh
        - mountPath: /bitnami/zookeeper
          name: data
      enableServiceLinks: true
      initContainers: null
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      serviceAccountName: zookeeper-team1
      volumes:
      - emptyDir: {}
        name: empty-dir
      - configMap:
          defaultMode: 493
          name: zookeeper-team1-scripts
        name: scripts
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  volumeClaimTemplates:
  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: data
    spec:
      accessModes:
      - ReadWriteOnce
      resources:
        requests:
          storage: 8Gi
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  labels:
    app.kubernetes.io/component: zookeeper
    app.kubernetes.io/instance: zookeeper-team1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/version: 3.9.3
    helm.sh/chart: zookeeper-13.6.0
  name: zookeeper-team1
  namespace: zookeeper
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: zookeeper
      app.kubernetes.io/instance: zookeeper-team1
      app.kubernetes.io/name: zookeeper
---
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  labels:
    app.kubernetes.io/instance: zookeeper-team1
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: zookeeper
    app.kubernetes.io/version: 3.9.3
    helm.sh/chart: zookeeper-13.6.0
  name: zookeeper-team1
  namespace: zookeeper
spec:
  egress:
  - {}
  ingress:
  - ports:
    - port: 2181
  - from:
    - podSelector:
        matchLabels:
          app.kubernetes.io/instance: zookeeper-team1
          app.kubernetes.io/name: zookeeper
    ports:
    - port: 2888
    - port: 3888
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: zookeeper-team1
      app.kubernetes.io/name: zookeeper
  policyTypes:
  - Ingress
  - Egress
